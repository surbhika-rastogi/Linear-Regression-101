# -*- coding: utf-8 -*-
"""Assignment_1_Instructions_Template_v3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1L877Nx7GtcqLS5LgaAf2bk2_y8AvOtXV

#**EE769 Introduction to Machine Learning**

#Assignment 1: Gradient Descent, Linear Regression, and Regularization


**Template and Instructions**



1. Up to two people can team up, but only one should submit, and both should understand the entire code.
2. Every line of code should end in a comment explaining the line
3. It is recommended to solve the assignment in Google Colab.
Write your roll no.s separated by commas here: 
4. Write your names here: 
5. There are two parts to the assignment. In the Part 1, the code format has to be strictly followed to enable auto-grading. In the second part, you can be creative.
6. **You can discuss with other groups or refer to the internet without being penalized, but you cannot copy their code and modify it. Write every line of code and comment on your own.**

#**Part 1 begins ...**
**Instructions to be strictly followed:**

1. Do not add any code cells or markdown cells until the end of this part. Especially, do not change the blocks that say "TEST CASES, DO NOT CHANGE"
2. In all other cells only add code where it says "CODE HERE".
3. If you encounter any raise NotImplementedError() calls you may comment them out.

We cannot ensure correct grading if you change anything else, and you may be penalised for not following these instructions.

## Import Statements
"""

import numpy as np
import pandas as pd
from matplotlib import pyplot as plt

"""## Normalize function 


"""

def Normalize(X): # Output should be a normalized data matrix of the same dimension
    '''
    Normalize all columns of X using mean and standard deviation
    '''
    # YOUR CODE HERE
    X= (np.array(X)).astype(np.float) #convert to float type
    if X.ndim == 1: #for 1D array, no need of for loop
      col = 1
      mean = np.mean(X)
      sigma = np.std(X)
      X = (X-mean)/sigma #assuming gaussian distribution
    else:
      col = np.shape(X)[1]
      for i in range(col): #iterate over all columns in X
        mean = np.mean(X[:,i])  
        sigma = np.std(X[:,i])
        X[:,i] = (X[:,i]-mean)/sigma #assuming gaussian distribution for each column
    return X
    raise NotImplementedError()

'''
TEST CASES, DO NOT CHANGE
'''
''' case 1 - 1 dimensional array'''
#X=np.array([[1,2,3],[3,4,5],[7,8,9]])
X1=np.array([1,2,3])
np.testing.assert_array_almost_equal(Normalize(X1),np.array([-1.224,  0.      ,  1.224]),decimal=3)
''' case 2 - 2 dimensional array'''
X2=np.array([[4,7,6],[3,8,9],[5,11,10]])
np.testing.assert_array_almost_equal(Normalize(X2),np.array([[ 0.  , -0.980581, -1.372813],[-1.224745, -0.392232,  0.392232],[ 1.224745,  1.372813,  0.980581]]))
''' case 3 - 1 dimensional array with float'''
X3=np.array([5.5,6.7,3.2,6.7])
np.testing.assert_array_almost_equal(Normalize(X3),np.array([-0.017,  0.822, -1.627,  0.822]),decimal=3)

"""## Prediction Function

Given X and w, compute the predicted output. Do not forget to add 1's in X
"""

def Prediction (X, w): # Output should be a prediction vector y
    '''
    Compute Prediction given an input datamatrix X and weight vecor w. Output y = [X 1]w where 1 is a vector of all 1s 
    '''
    # YOUR CODE HERE
    X_col = X.shape[1]
    w_len = len(w)
    for i in range(w_len - X_col): #if there are non-zero bias weights present in w, then add equivalent number of 'ones' columns in X
      X = np.c_[X, np.ones(X.shape[0])]

    return np.dot(X, w) #y = w[X]
    raise NotImplementedError()

'''
TEST CASES, DO NOT CHANGE
'''
''' case 1 - Known input output matrix and weights 1'''
X1 = np.array([[3,2],[1,1]])
w1 = np.array([2,1,1]) 
np.testing.assert_array_equal(Prediction(X1,w1),np.array([9,4]))

"""## Loss Functions

Code the four  loss functions:

1. MSE loss is only for the error
2. MAE loss is only for the error
3. L2 loss is for MSE and L2 regularization, and can call MSE loss
4. L1 loss is for MSE and L1 regularization, and can call MSE loss
"""

def MSE_Loss (X, t, w, lamda =0): # Ouput should be a single number
    '''
    lamda=0 is a default argument to prevent errors if you pass lamda to a function that doesn't need it by mistake. 
    This allows us to call all loss functions with the same input format.
    
    You are encouraged read about default arguments by yourself online if you're not familiar.
    '''
    # YOUR CODE HERE
    y = Prediction(X,w) #prediction value
    mse = (np.sum((y-t)**2))/(y.size) #mse is the average/mean of square of error in predicted and target value
    return mse
    raise NotImplementedError()

'''
TEST CASES, DO NOT CHANGE
'''
''' case 1 '''
X=np.array([[3,6,5],[4.5,6.6,6]])
t=np.array([4,5.5])
w=np.array([2,-1,0.5,1])
np.testing.assert_almost_equal(MSE_Loss(X,t,w),0.53,decimal=3)

def MAE_Loss (X, t, w, lamda = 0): # Output should be a single number
    # YOUR CODE HERE
    y = Prediction(X,w) #prediction value
    mae = (np.sum(np.absolute(y-t)))/(y.size) #mae is mean/avaerage of absolute value of error between predicted and actual value
    return mae
    raise NotImplementedError()

'''
TEST CASES, DO NOT CHANGE
'''
''' case 1 '''
X=np.array([[3,6,5],[4.5,6.6,6]])
t=np.array([4,5.5])
w=np.array([2,-1,0.5,1])
np.testing.assert_almost_equal(MAE_Loss(X,t,w),0.700,decimal=3)

def L2_Loss (X, t, w, lamda): # Output should be a single number based on L2-norm (with sqrt)
    ''' Need to specify what inputs are'''
    # YOUR CODE HERE
    mse = MSE_Loss(X, t, w) #mse loss
    mse_L2 = mse + (lamda * np.sqrt(np.sum(w[:-1]**2))) #L2 regularization is lamda times sum of square weight vectors without bias
    return mse_L2
    raise NotImplementedError()

'''
TEST CASES, DO NOT CHANGE
'''
''' case 1 '''
X=np.array([[3,6,5],[4.5,6.6,6]])
t=np.array([4,5.5])
w=np.array([2,-1,0.5,1])
np.testing.assert_almost_equal(L2_Loss(X,t,w,0.5),1.675,decimal=3)

def L1_Loss (X, t, w, lamda): # Output should be a single number
    # YOUR CODE HERE
    mse = MSE_Loss(X, t, w) #mse loss
    mse_L1 = mse + (lamda * (np.sum(np.absolute(w[:-1])))) #L1 regularization is lamda times sum of absolute weight vectors without bias
    return mse_L1
    raise NotImplementedError()

'''
TEST CASES, DO NOT CHANGE
'''
''' case 1 '''
X=np.array([[3,6,5],[4.5,6.6,6]])
t=np.array([4,5.5])
w=np.array([2,-1,0.5,1])
np.testing.assert_almost_equal(L1_Loss(X,t,w,0.5),2.280,decimal=3)

def NRMSE_Metric (X, t, w, lamda=0): # Output should be a single number. RMSE/std_dev(t)
    # YOUR CODE HERE
    mse = MSE_Loss (X, t, w) #mse loss
    y = Prediction(X,w) #predicted values
    nrmse = np.sqrt(mse)/np.std(t) #normalised mean square error
    return nrmse
    raise NotImplementedError()

'''
TEST CASES, DO NOT CHANGE
'''
''' Test case 1 '''
X=np.array([[3,6,5],[4.5,6.6,6]])
t=np.array([4,5.5])
w=np.array([2,-1,0.5,1])
np.testing.assert_almost_equal(NRMSE_Metric(X,t,w,0.5),0.970,decimal=3)

"""## Gradient function
Each Loss function will have its own gradient function:

1. MSE gradient is only for the error
2. MAE gradient is only for the error
3. L2 gradient is for MSE and L2 regularization, and can call MSE gradient
4. L1 gradient is for MSE and L1 regularization, and can call MSE gradient
"""

def MSE_Gradient (X, t, w, lamda=0): # Output should have the same size as w
    # YOUR CODE HERE
    # reference for formula: https://math.stackexchange.com/questions/1962877/compute-the-gradient-of-mean-square-error
    y = Prediction(X,w) #predicted value
    e = t - y #error differenc in target and predicted value

    X_col = X.shape[1]
    w_len = len(w)

    for i in range(w_len - X_col): 
      #if there are non-zero bias weights present in w, then add equivalent number of 'ones' columns in X
      X = np.c_[X, np.ones(X.shape[0])]

    grad = -2* np.dot((np.transpose(X)),e)/y.size #gradient = (X'.e)/n
    
    return grad
    raise NotImplementedError()

'''
TEST CASES, DO NOT CHANGE
'''
''' case 1 '''
X=np.array([[3,6,5],[4.5,6.6,6]])
t=np.array([4,5.5])
w=np.array([2,-1,0.5,1])
np.testing.assert_array_almost_equal(MSE_Gradient(X,t,w),np.array([2.55, 2.94, 2.9 , 0.4 ]),decimal=3)

def MAE_Gradient (X, t, w, lamda=0): # Output should have the same size as w
    # YOUR CODE HERE
    y = Prediction(X,w)
    X_col = X.shape[1]
    w_len = len(w)
    for i in range(w_len - X_col):
      #if there are non-zero bias weights present in w, then add equivalent number of 'ones' columns in X
      X = np.c_[X, np.ones(X.shape[0])]

    grad_y = -0.5*np.sign(t-y) #grad w.r.t. y = - sigmoid function of error/2
    grad_w = np.dot(grad_y, X) #grad w.r.t weight = (grad w.r.t. y).X
    return grad_w
    raise NotImplementedError()

'''
TEST CASES, DO NOT CHANGE
'''
''' case 1 '''
X=np.array([[3,6,5],[4.5,6.6,6]])
t=np.array([4,5.5])
w=np.array([2,-1,0.5,1])
np.testing.assert_array_almost_equal(MAE_Gradient(X,t,w),np.array([0.75,  0.3 ,  0.5 , 0.]),decimal=3)

def L2_Gradient (X, t, w, lamda): # Output should have the same size as w
    # YOUR CODE HERE
    mse_grad = MSE_Gradient(X,t,w) #mse gradient
    l2_penalty = lamda*np.append((w[:-1]),0)/np.sqrt(np.sum(w[:-1]**2)) #gradient of L2 regularisation term = w/sqrt(sum of square of w)
    
    return mse_grad + l2_penalty #L2 gradient = mse gradient + gradient of L2 regularisation term
    raise NotImplementedError()

'''
TEST CASES, DO NOT CHANGE
'''
''' case 1 '''
X=np.array([[3,6,5],[4.5,6.6,6]])
t=np.array([4,5.5])
w=np.array([2,-1,0.5,1])
np.testing.assert_array_almost_equal(L2_Gradient(X,t,w,0.5),np.array([2.986, 2.721, 3.009 , 0.4 ]),decimal=3)

def L1_Gradient (X, t, w, lamda): # Output should have the same size as w
    # YOUR CODE HERE
    mse_grad = MSE_Gradient(X,t,w) #mse gradient
    l1_penalty = lamda * np.sign(np.append(w[:-1],0)) #gradient of L1 regularisation term = sigmoid function of w
    
    return (mse_grad + l1_penalty) #L1 gradient = mse gradient + gradient of L1 regularisation term
    raise NotImplementedError()

'''
TEST CASES, DO NOT CHANGE
'''
''' case 1 '''
X=np.array([[3,6,5],[4.5,6.6,6]])
t=np.array([4,5.5])
w=np.array([2,-1,0.5,1])
np.testing.assert_array_almost_equal(L1_Gradient(X,t,w,0.5),np.array([3.05, 2.44, 3.4 , 0.4 ]),decimal=3)

"""## Gradient Descent Function

"""

def Gradient_Descent (X, X_val, t, t_val, w, lamda, max_iter, epsilon, lr, lossfunc, gradfunc): # See output format in 'return' statement
    # YOUR CODE HERE

    #Initialize losses
    current_loss = 0
    previous_loss = 0

    for i in range(max_iter): #iterate upto maximum iterations
      current_loss = lossfunc(X, t, w, lamda) #calculate present loss
      #print(current_loss)
      if (previous_loss and abs(current_loss - previous_loss) <= epsilon): #early stopping of training function if error terms are constant upto epsilon value
        break
      previous_loss = current_loss
      w = w - lr * gradfunc(X, t, w, lamda) #updation of weights 

    w_final = w
    train_loss_final = lossfunc(X, t, w, lamda) #calculation of training loss


    validation_loss_final = lossfunc(X_val, t_val, w, lamda) #calculation of validation loss
    validation_NRMSE = NRMSE_Metric(X_val, t_val, w, lamda) #calculation of NRMSE metric

    #print(i)
    return w_final, train_loss_final, validation_loss_final, validation_NRMSE #You should return variables structured like this.
    raise NotImplementedError()

'''
TEST CASES, DO NOT CHANGE
'''
X=np.array([[23,24],[1,2]])
t=np.array([4,5])
X_val=np.array([[3,4],[5,6]])
t_val=np.array([3,4])
w=np.array([3,2,1])
results =Gradient_Descent (X, X_val, t, t_val, w, 0.1, 100, 1e-10, 1e-5, L2_Loss,L2_Gradient) 
print(results)
np.testing.assert_allclose([results[1]],[697.919],rtol =0.05)
np.testing.assert_allclose([results[2]],[20],atol=5) # we expect around 17.5  but some students got 24 which we will also accept
#Instructor Values of results[1] and results [2] are 697.919 and 17.512 respectively

"""## Pseudo Inverse Method

You have to implement a slightly more advanced version, with L2 penalty:

w = (X' X + lambda I)^(-1) X' t.

See, for example: Section 2 of https://web.mit.edu/zoya/www/linearRegression.pdf

Here, the column of 1's in assumed to be included in X
"""

def Pseudo_Inverse (X, t, lamda): # Output should be weight vector
    # YOUR CODE HERE
    X = np.c_[X, np.ones(X.shape[0])] #append one extra column (each element equal one) for bias 
    X_col = X.shape[1]

    w = np.dot(np.dot((np.linalg.inv(np.dot(np.transpose(X),X)+ lamda*np.identity(X.shape[1]))),np.transpose(X)),t) #weight calculation using equation: w = (X' X + lambda I)^(-1) X' t.
    return w
    raise NotImplementedError()

'''
TEST CASES, DO NOT CHANGE
'''
''' case 1 - other data'''
X=np.array([[3,6,5],[4.5,6.6,6]])
t=np.array([4,5.5])
np.testing.assert_array_almost_equal(Pseudo_Inverse(X,t,0.5),np.array([ 0.491,  0.183,  0.319, -0.002]),decimal=3)

"""#... Part 1 ends Below this you be more creative. Just comment out the lines where you save files (e.g. test predictions).

#**Part 2 begins ...**

**Instructions to be loosely followed (except number 8):**

1. Add more code and text cells between this and the last cell.
2. Read training data from: https://www.ee.iitb.ac.in/~asethi/Dump/TempTrain.csv only. Do not use a local copy of the dataset.
3. Find the best lamda for **MSE+lamda*L2(w)** loss function. Plot training and validation RMSE vs. 1/lamda (1/lamda represents model complexity). Print weights, validation RMSE, validation NRMSE for the best lamda.
4. Find the best lamda for **MSE+lamda*L1(w)** loss function. Plot training and validation RMSE vs. 1/lamda (1/lamda represents model complexity). Print weights, validation RMSE, validation NRMSE for the best lamda.
5. Find the best lamda for the **pseudo-inv method**. Plot training and validation RMSE vs. 1/lamda (1/lamda represents model complexity). Print weights, validation RMSE, validation NRMSE for the best lamda.
6. Write your observations and conclusions.
7. Read test data from: https://www.ee.iitb.ac.in/~asethi/Dump/TempTest.csv only. Do not use a local copy of the dataset. Predict its dependent (missing last column) using the model with the lowest MSE, RMSE, or NRMSE. Save it as a file RollNo1_RollNo2_1.csv.
8. **Disable the prediction csv file saving statement and submit this entire .ipynb file, .py file, and .csv file as a single RollNo1_RollNo2_1.zip file.**
"""

df = pd.read_csv("https://www.ee.iitb.ac.in/~asethi/Dump/TempTrain.csv") #read the training data

#randomizing the dataset before splitting into train and test
np.random.seed(0) #seed for fixing random values
msk = np.random.rand(len(df)) < 0.8 #create mask of 80% values randomly sampled from train data file

# splitting dataframe into train and test
train = df[msk] #use 80% mask to separate training data
test = df[~msk] #use invereted mask to separate remaining data for testing

# train = df[:4861]
# test = df[4861:]

train #training data visualisation as dataframe

#separating input and output values of model for test and train dataframe

#and removing the title bar from data
X_train = train.drop('Next_Tmax', axis=1) 
y_train = train['Next_Tmax'] 

X_test = test.drop('Next_Tmax', axis=1) 
y_test = test['Next_Tmax']

X_train #input train vector dataframe

#converting dataframe to numpy for faster computation
X_train = X_train.to_numpy()
y_train = y_train.to_numpy()

X_test = X_test.to_numpy()
y_test = y_test.to_numpy()

X_train_org = X_train #storing original copy of training data

print(f"{min(y_train)} , {max(y_train)}") #max and minimum output balues

#Normalising the input training vectors:
#X_train =X_train/(np.linalg.norm(X_train))
#X_train /=  X_train.sum(axis=1)[:,np.newaxis]

X_train = Normalize(X_train) #normalise the input training vector
X_train

#X_test =X_test/(np.linalg.norm(X_test))
#X_test /=  X_test.sum(axis=1)[:,np.newaxis]

#normalise the testing data using the mean and sigma of training data
#assuming that the distribution of test data is unknown beforehand
col = np.shape(X_train)[1]
for i in range(col):
  mean = np.mean(X_train_org[:,i]) #mean of train data
  sigma = np.std(X_train_org[:,i]) #sigma of training data
  X_test[:,i] = (X_test[:,i]-mean)/sigma #normalisation of test data assuming gaussian distribution same as train data

X_train.shape #verifying shape of train data

X_test.shape #verifying shape of train data

X_test #visualisation of testing data after normalisation

def Gradient_Descent2 (X, X_val, t, t_val, w, lamda, max_iter, epsilon, lr, lossfunc, gradfunc, trainlossfunc, vallossfunc): # See output format in 'return' statement
    # YOUR CODE HERE

    current_loss = 0
    previous_loss = 0
    for i in range(max_iter): #iterate upto maximum iterations
      current_loss = lossfunc(X, t, w, lamda) #calculate present loss
      #print(current_loss)
      if (previous_loss and abs(current_loss - previous_loss) <= epsilon): #early stopping of training function if error terms are constant upto epsilon value
        break
      previous_loss = current_loss
      w = w - lr * gradfunc(X, t, w, lamda) #updation of weights

    w_final = w
    
    train_loss_final = trainlossfunc(X, t, w, lamda) #calculation of training loss

    validation_loss_final = vallossfunc(X_val, t_val, w, lamda) #calculation of validation loss
    validation_NRMSE = NRMSE_Metric(X_val, t_val, w, lamda) #calculation of NRMSE metric

    #print(i)
    return w_final, train_loss_final, validation_loss_final, validation_NRMSE #You should return variables structured like this.
    raise NotImplementedError()

"""Part B - (3) Find the best lamda for MSE+lamda*L2(w) loss function. Plot training and validation RMSE vs. 1/lamda (1/lamda represents model complexity). Print weights, validation RMSE, validation NRMSE for the best lamda."""

max_iter = 100

#loss functions to be used for verifying accuracy of model
lossfunc = L2_Loss #loss function
gradfunc = L2_Gradient #gradient function
trainlossfunc = MSE_Loss #training loss calculation function
vallossfunc = MSE_Loss #validation loss calculation function

lr = 0.1 #learning rate

epsilon = 1e-10 #training stop error limit

#lists for storing the loss and weights for plotting the graph
train_loss = []
val_loss = []
l=[]
weights = []

#initialise weights of the Gradient Descent with unity vector
w = np.ones(X_train.shape[1]+1)

lamda = 0.5e-1 #regularisation coefficient initialisation

for j in range(15): #iterate over lamda values

  result = Gradient_Descent2(X_train, X_test, y_train, y_test, w, lamda, max_iter, epsilon, lr, lossfunc, gradfunc, trainlossfunc, vallossfunc)
  #argument: X, X_val, t, t_val, w, lamda, max_iter, epsilon, lr, lossfunc, gradfunc
  #result: w_final, train_loss_final, validation_loss_final, validation_NRMSE

 # print(f'lamda: {lamda} , training_loss: {pres_train_loss}, validation_loss:{pres_val_loss}')
  print(f'lamda: {lamda} , training_loss: {np.sqrt(result[1])} , validation_loss: {np.sqrt(result[2])} , validation_NRMSE: {result[3]}, weights: ')

  train_loss.append(np.sqrt(result[1]))
  val_loss.append(np.sqrt(result[2]))
  l.append(lamda)
  lamda = lamda/1.5 #update lamda value
  weights.append(result[0])

fig, (ax1, ax2) = plt.subplots(2, sharex=True)
fig.set_size_inches(18.5, 10.5)
fig.suptitle('Training and Validation loss vs 1/lamda')
ax1.plot(np.reciprocal(l), train_loss, label = 'training loss')
ax2.plot(np.reciprocal(l),val_loss, label='validation loss')
ax1.set_title('training loss')
ax2.set_title('validation loss')
ax1.set_xlabel('1/lamda')
ax2.set_xlabel('1/lamda')
ax1.set_ylabel('RMSE')
ax2.set_ylabel('RMSE')
# ax1.xlabel('1/lamda')
# ax1.ylabel('Training Loss')
# ax2.xlabel('1/lamda')
# ax2.ylabel('Validation Loss')

# plt.figure(figsize=(21,8))
# #plt.plot(np.reciprocal(l), train_loss, label = 'training loss')
# plt.plot(np.reciprocal(l),val_loss, label='validation loss')
# plt.xlabel('1/lamda')
# plt.ylabel('Loss')
# plt.title('L2 loss')

#plt.legend()
plt.show()

print(f'Minimum value of validation loss: {np.min(val_loss)}')

#Best lamda : 0.0065 obtimised where validation loss is minimum
L2_lamda = 0.0065
w = np.ones(X_train.shape[1]+1)

#best weights
result = Gradient_Descent2(X_train, X_test, y_train, y_test, w, L2_lamda, max_iter, epsilon, lr, lossfunc, gradfunc, trainlossfunc, vallossfunc)
print( f'best lamda: 0.0065 , weights : {result[0]}')
#print(result)
L2_weights = result[0]

"""Part 2 -(4) Find the best lamda for MSE+lamda*L1(w) loss function. Plot training and validation RMSE vs. 1/lamda (1/lamda represents model complexity). Print weights, validation RMSE, validation NRMSE for the best lamda."""

max_iter = 100

#loss functions to be used for verifying accuracy of model
lossfunc = L1_Loss #loss function
gradfunc = L1_Gradient #gradient function
trainlossfunc = MSE_Loss #training loss calculation function
vallossfunc = MSE_Loss #validation loss calculation function

lr = 1e-1 #learning rate

epsilon = 1e-10 #training stop error limit

#lists for storing the loss and weights for plotting the graph
train_loss = []
val_loss = []
l=[]
weights = []

#initialise weights of the Gradient Descent with unity vector
w = np.ones(X_train.shape[1]+1)

#regularisation coefficient initialisation
lamda = 1

for j in range(20): #iterate over lamda values

  result = Gradient_Descent2(X_train, X_test, y_train, y_test, w, lamda, max_iter, epsilon, lr, lossfunc, gradfunc, trainlossfunc, vallossfunc)
  #argument: X, X_val, t, t_val, w, lamda, max_iter, epsilon, lr, lossfunc, gradfunc
  #result: w_final, train_loss_final, validation_loss_final, validation_NRMSE

 # print(f'lamda: {lamda} , training_loss: {pres_train_loss}, validation_loss:{pres_val_loss}')
  print(f'lamda: {lamda} , training_loss: {np.sqrt(result[1])} , validation_loss: {np.sqrt(result[2])} , validation_NRMSE: {result[3]}')

  train_loss.append(np.sqrt(result[1]))
  val_loss.append(np.sqrt(result[2]))
  l.append(lamda)
  lamda = lamda/1.5 #update lamda factor
  weights.append(result[0])

#plot the validation vs 1/lamda curve
# plt.plot(np.reciprocal(l), train_loss, label = 'training loss')
# plt.plot(np.reciprocal(l),val_loss, label='validation loss')
# plt.xlabel('1/lamda')
# plt.ylabel('Loss')
# plt.title('L1 loss')

# plt.legend()
# plt.show()
fig, (ax1, ax2) = plt.subplots(2, sharex=True)
fig.set_size_inches(18.5, 10.5)
fig.suptitle('Training and Validation loss vs 1/lamda for L1 regularised Gradient Descent')
ax1.plot(np.reciprocal(l), train_loss, label = 'training loss')
ax2.plot(np.reciprocal(l),val_loss, label='validation loss')
ax1.set_title('training loss')
ax2.set_title('validation loss')
ax1.set_xlabel('1/lamda')
ax2.set_xlabel('1/lamda')
ax1.set_ylabel('RMSE')
ax2.set_ylabel('RMSE')

plt.show()

print(f'Minimum value of validation loss: {np.min(val_loss)}')

#Best lamda : 0.017 
L1_lamda = 0.017
w = np.ones(X_train.shape[1]+1)

#best weights
result = Gradient_Descent2(X_train, X_test, y_train, y_test, w, L1_lamda, max_iter, epsilon, lr, lossfunc, gradfunc, trainlossfunc, vallossfunc)
print( f'best lamda: 0.48 , weights : {result[0]}')
#print(result)
L1_weights = result[0]

"""Part B - (5) Find the best lamda for the pseudo-inv method. Plot training and validation RMSE vs. 1/lamda (1/lamda represents model complexity). Print weights, validation RMSE, validation NRMSE for the best lamda."""

#loss functions to be used for verifying accuracy of model
trainlossfunc = MSE_Loss
vallossfunc = MSE_Loss

#lists for storing the loss and weights for plotting the graph
train_loss = []
val_loss = []
l=[]
weights = []

#initialise weights of the Gradient Descent with unity vector
w = np.ones(X_train.shape[1]+1)

#regularisation coefficient initialisation
lamda = 100

for j in range(10): #iterate over lamda values

  w = Pseudo_Inverse(X_train,y_train,lamda) #calculation of weights using Pseudo inverse algorithm

  train_l = trainlossfunc(X_train, y_train, w, lamda) #calculation of training loss 

  validation_l = vallossfunc(X_test, y_test, w, lamda) #calculation of validation loss 
  validation_NRMSE = NRMSE_Metric(X_test, y_test, w, lamda) #calculation of validation NRMSE 

 # print(f'lamda: {lamda} , training_loss: {pres_train_loss}, validation_loss:{pres_val_loss}')
  print(f'lamda: {lamda} , training_loss: {np.sqrt(train_l)} , validation_loss: {np.sqrt(validation_l)} , validation_NRMSE: {validation_NRMSE}')

  train_loss.append(np.sqrt(train_l))
  val_loss.append(np.sqrt(validation_l))
  l.append(lamda)
  lamda = lamda/2 #updation of lamda value
  weights.append(w)

#plot loss vs 1/lamda curve
# plt.plot(np.reciprocal(l), train_loss, label = 'training loss')
# plt.plot(np.reciprocal(l),val_loss, label='validation loss')
# plt.xlabel('1/lamda')
# plt.ylabel('Loss')
# plt.title('Pseudo inverse loss')

# plt.legend()
# plt.show()
fig, (ax1, ax2) = plt.subplots(2, sharex=True)
fig.set_size_inches(18.5, 10.5)
fig.suptitle('Training and Validation loss vs 1/lamda for Psuedo Inverse method')
ax1.plot(np.reciprocal(l), train_loss, label = 'training loss')
ax2.plot(np.reciprocal(l),val_loss, label='validation loss')
ax1.set_title('training loss')
ax2.set_title('validation loss')
ax1.set_xlabel('1/lamda')
ax2.set_xlabel('1/lamda')
ax1.set_ylabel('RMSE')
ax2.set_ylabel('RMSE')

plt.show()

print(f'Minimum value of validation loss: {np.min(val_loss)}')

#Best lamda : 6.25 
PI_lamda = 6.25
w = Pseudo_Inverse(X_train,y_train,lamda)
print( f'best lamda: 6.25 , weights : {w}')
#print(result)
PI_weights = w

"""# Write your observations and conclusions.

Training of following 3 models is done: 

1) L1 regularise Gradient Descent

2) L2 regularise Gradient Descent

3) Psuedo inverse method



---



Following observations were done:

1) Losses are a convext function of 1/lamda. Therefore it required to perform optimisation of the regularisation coefficient i.e. lamda for a given learning rate to reach minimum error in results.

2) Learning rate should be optimised such that it is not too less and not too more. Low values of learning rate are not able to reach the minimum of loss function and results in large errors. Also, high values of the learning rate will lead to escaping of the minimum as the weight updation steps are too large.

3) With the given training dataset, similar results of MSE and prediction were found. It is concluded that the performance of a certain ML model depends upon the extent of optimisation also and not just the model type.

Prediction
"""

#read the testing data
df2 = pd.read_csv("https://www.ee.iitb.ac.in/~asethi/Dump/TempTest.csv")

#converting the pandas dataframe to numpy format
X_pred = df2.to_numpy()

col = np.shape(X_train_org)[1] #columns in input vector

#NOrmalisation of input vector using distribution parameters of training data (assuming similar distribution)
for i in range(col):
  mean = np.mean(X_train_org[:,i]) #mean of training data
  sigma = np.std(X_train_org[:,i]) #sigma of training data
  X_pred[:,i] = (X_pred[:,i]-mean)/sigma #normalisation of test data
print(X_pred) #verify normalised input vector

"""# 6) Read test data from: https://www.ee.iitb.ac.in/~asethi/Dump/TempTest.csv only. Do not use a local copy of the dataset. Predict its dependent (missing last column) using the model with the lowest MSE, RMSE, or NRMSE. Save it as a file RollNo1_RollNo2_1.csv.


"""

#Selection of best model based on MSE loss:

L2model_mse = MSE_Loss (X_train, y_train, L2_weights, lamda =L2_lamda)
L1model_mse = MSE_Loss (X_train, y_train, L1_weights, lamda =L1_lamda)
PImodel_mse = MSE_Loss (X_train, y_train, PI_weights, lamda =PI_lamda)

L2model_rmse = np.sqrt(MSE_Loss (X_train, y_train, L2_weights, lamda =L2_lamda))
L1model_rmse = np.sqrt(MSE_Loss (X_train, y_train, L1_weights, lamda =L1_lamda))
PImodel_rmse = np.sqrt(MSE_Loss (X_train, y_train, PI_weights, lamda =PI_lamda))

L2model_nrmse = NRMSE_Metric (X_train, y_train, L2_weights, lamda =L2_lamda)
L1model_nrmse = NRMSE_Metric (X_train, y_train, L1_weights, lamda =L1_lamda)
PImodel_nrmse = NRMSE_Metric (X_train, y_train, PI_weights, lamda =PI_lamda)

print( f"MSE loss for=>  L2 model: {L2model_mse} , L1 model: {L1model_mse} , Psuedo inverse model: {PImodel_mse} ")
print( f"MSE loss for=>  L2 model: {L2model_rmse} , L1 model: {L1model_rmse} , Psuedo inverse model: {PImodel_rmse} ")
print( f"MSE loss for=>  L2 model: {L2model_nrmse} , L1 model: {L1model_nrmse} , Psuedo inverse model: {PImodel_nrmse} ")

y_pred = Prediction(X_pred , L2_weights) #prediction using L2 loss model
#print(y_pred)
#plt.plot(np.multiply(y_pred,factor[:,0]))
print(f'max: {max(y_pred)}, min: {min(y_pred)}') #print range of prediction data
plt.plot(y_pred) #plot prediction data

"""Prediction with L1 model"""

y_pred = Prediction(X_pred , L1_weights) #prediction using L1 loss model
#print(y_pred)
print(f'max: {max(y_pred)}, mine: {min(y_pred)}') #print range of prediction data
plt.plot(y_pred) #plot prediction data

"""Prediction with Pseudo Inverse (best model)"""

y_pred = Prediction(X_pred , PI_weights) #prediction using Psuedo Inverse model
#print(y_pred)
print(f'max: {max(y_pred)}, min: {min(y_pred)}') #print range of prediction data
plt.plot(y_pred) #plot prediction data

"""Save to .csv file"""

pred_data_write = np.append(X_pred, np.transpose(y_pred[np.newaxis]), axis=1) # Appending the ouput values in the file.
pred_data_write_df = pd.DataFrame(np.transpose(y_pred[np.newaxis])) # Creating dataframe from numpy array.
h = train.columns.values # Getting the header from given link
#pred_data_write_df.to_csv("213070056_213079013_1.csv",header=['Next_Tmax'],index=False) # Writing dataframe to csv file.

"""# Calculate R^2 value"""

#best model is the one with least MSE i.e. PI model
Best_model_weights = PI_weights

ybar = np.mean(y_test) #mean of actual test output vector
ycap = Prediction(X_test, Best_model_weights) #predicted output vector

#plot target and predicted data

plt.plot(ycap, label = 'predicted')
plt.plot(y_test, label='actual')

plt.legend()
plt.show()

#coefficient of regression calculation
#formula reference: https://stackoverflow.com/questions/40901445/function-to-calculate-r2-r-squared-in-r
R_sq = np.sum((ycap - ybar)**2)/np.sum((y_test - ybar)**2)

print(R_sq)

"""Hence, the R^2 value is 0.795

#**... Part 2 ends.**

1. Write the name or roll no.s of friends from outside your group with whom you discussed the assignment here (no penalty for mere discussion without copying code): 
 Rahul Singh (213070052)

2. Write the links of sources on the internet referred here (no penalty for mere consultation without copying code): 
https://stackoverflow.com/questions/21494489/what-does-numpy-random-seed0-do
https://stackoverflow.com/questions/21494489/what-does-numpy-random-seed0-do
"""

